{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Luna_pretrained_BERT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNi0hdsUdoIbOx+RpWdjyCp",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3f3d508768c849ca93546aec19ef4707": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1e96f526187542c0a7421a335c4d88ac",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b412d66909e343fdb885543e9073afe8",
              "IPY_MODEL_1862f780f69d4cb6b1c95db1f1702c7e"
            ]
          }
        },
        "1e96f526187542c0a7421a335c4d88ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b412d66909e343fdb885543e9073afe8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_283605c1bda345f39152f3b6bb584f01",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a9f14435d3b545bab8a302a94c4a46ac"
          }
        },
        "1862f780f69d4cb6b1c95db1f1702c7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cedba0b514094f788c30827096c69a9f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 2.20MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4c56e469c5d34e62ae77230b0bca56dc"
          }
        },
        "283605c1bda345f39152f3b6bb584f01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a9f14435d3b545bab8a302a94c4a46ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cedba0b514094f788c30827096c69a9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4c56e469c5d34e62ae77230b0bca56dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ec0151086a6b4ad290badde1cf42563d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b755eb914c8741c8a3f45830c75c8162",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b0554325507447258133dfffa3e3cd05",
              "IPY_MODEL_eeee01d649224622b319b8affc0fcfa4"
            ]
          }
        },
        "b755eb914c8741c8a3f45830c75c8162": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b0554325507447258133dfffa3e3cd05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3d0c3db2d49945109c326f8c73e120ef",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c6357afd5b104d35ae478b56237614cf"
          }
        },
        "eeee01d649224622b319b8affc0fcfa4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c76e6c3afd16489e9ba044d6c8805d75",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 1.27kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_92989386ef5a439a8ccb4bd092cf537b"
          }
        },
        "3d0c3db2d49945109c326f8c73e120ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c6357afd5b104d35ae478b56237614cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c76e6c3afd16489e9ba044d6c8805d75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "92989386ef5a439a8ccb4bd092cf537b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6870f8ea57f14dcbba1e27c579d81626": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_84ec3ccb97c34519bbca1f42586cdf1e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_608b6a7a7fa24d95a945e57f1ee06a00",
              "IPY_MODEL_c44b2d73a76244d69c8d78ea313a9a64"
            ]
          }
        },
        "84ec3ccb97c34519bbca1f42586cdf1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "608b6a7a7fa24d95a945e57f1ee06a00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_62e42e47315a428498c9d69c4999b49a",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fe837a4e6dd140408964c5a41204fab5"
          }
        },
        "c44b2d73a76244d69c8d78ea313a9a64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d936c7efe68b470cbbf7252fe04aab82",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:07&lt;00:00, 61.2MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f8ac27b1bb6f4013a4219f337a7576c3"
          }
        },
        "62e42e47315a428498c9d69c4999b49a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fe837a4e6dd140408964c5a41204fab5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d936c7efe68b470cbbf7252fe04aab82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f8ac27b1bb6f4013a4219f337a7576c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/L-ansari/NLP/blob/master/Luna_pretrained_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUwT_vy3GA1O"
      },
      "source": [
        "###Pre trained BERT model for full sentence multiclass classification\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tb_bqfFBV-gU",
        "outputId": "e6cfcf02-b165-4fae-d331-f333cfd1b703"
      },
      "source": [
        "from platform import python_version\n",
        "from pathlib import Path\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "import pathlib\n",
        "import pandas as pd\n",
        "#from pytorch_pretrained_bert import BertTokenizer\n",
        "import torch\n",
        "from pandas import DataFrame\n",
        "\n",
        "\n",
        "print(python_version())\n",
        "print (tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3.6.9\n",
            "2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gwLfAfnZElz",
        "outputId": "be9e5e31-1730-454e-d126-37da15b37f97"
      },
      "source": [
        "from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "drive.mount(\"/content/drive\", force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOB13ua3bYtQ"
      },
      "source": [
        "####Helper functions to read in the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPJhRSocZPaf"
      },
      "source": [
        "def read_data(directory):\n",
        "    ids = []\n",
        "    texts = []\n",
        "    labels = []\n",
        "    for f in directory.glob('*.txt'):\n",
        "        id = f.name.replace('article', '').replace('.txt','')\n",
        "        ids.append(id)\n",
        "        texts.append(f.read_text())\n",
        "        labels.append(parse_label(f.as_posix().replace('.txt', '.labels.tsv')))\n",
        "    # labels can be empty \n",
        "    return ids, texts, labels\n",
        "\n",
        "def clean_text(articles, ids):\n",
        "    texts = []\n",
        "    for article, id in zip(articles, ids):\n",
        "        sentences = article.split('\\n')\n",
        "        start = 0\n",
        "        end = -1\n",
        "        res = []\n",
        "        for sentence in sentences:\n",
        "           start = end + 1\n",
        "           end = start + len(sentence)  # length of sequence \n",
        "           if sentence != \"\": # if not empty line\n",
        "               res.append([id, sentence, start, end])\n",
        "        texts.append(res)\n",
        "    return texts\n",
        "\n",
        "\n",
        "def make_dataset(directory):\n",
        "    ids, texts, labels = read_data(directory)\n",
        "    texts = clean_text(texts, ids)\n",
        "    res = []\n",
        "    for text, label in zip(texts, labels):\n",
        "        # making positive examples\n",
        "        tmp = [] \n",
        "        pos_ind = [0] * len(text)\n",
        "        for l in label:\n",
        "            for i, sen in enumerate(text):\n",
        "                if l[0] >= sen[2] and l[0] < sen[3] and l[1] > sen[3]:\n",
        "                    l[4] = 1\n",
        "                    tmp.append(sen + [l[0], sen[3], l[2], l[3], l[4]])\n",
        "                    pos_ind[i] = 1\n",
        "                    l[0] = sen[3] + 1\n",
        "                elif l[0] != l[1] and l[0] >= sen[2] and l[0] < sen[3] and l[1] <= sen[3]: \n",
        "                    tmp.append(sen + l)\n",
        "                    pos_ind[i] = 1\n",
        "        # making negative examples\n",
        "        dummy = [0, 0, 'O', 0, 0]\n",
        "        for k, sen in enumerate(text):\n",
        "            if pos_ind[k] != 1:\n",
        "                tmp.append(sen+dummy)\n",
        "        res.append(tmp)     \n",
        "    return res\n",
        "  \n",
        "def parse_label(label_path):\n",
        "    labels = []\n",
        "    f= Path(label_path)\n",
        "    \n",
        "    if not f.exists():\n",
        "        return labels\n",
        "\n",
        "    for line in open(label_path):\n",
        "        parts = line.strip().split('\\t')\n",
        "        labels.append([int(parts[2]), int(parts[3]), parts[1], 0, 0])\n",
        "    labels = sorted(labels) \n",
        "\n",
        "    if labels:\n",
        "        length = max([label[1] for label in labels]) \n",
        "        visit = np.zeros(length)\n",
        "        res = []\n",
        "        for label in labels:\n",
        "            if sum(visit[label[0]:label[1]]):\n",
        "                label[3] = 1\n",
        "            else:\n",
        "               visit[label[0]:label[1]] = 1\n",
        "            res.append(label)\n",
        "        return res \n",
        "    else:\n",
        "        return labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnUTW4QmRX4t"
      },
      "source": [
        "####Importing train and test set and reading them in as dataframes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIMmocTPZWvh"
      },
      "source": [
        "#train set\n",
        "dataset_train=make_dataset(Path('/content/drive/My Drive/DSP/data/protechn_corpus_eval/train'))\n",
        "#test set\n",
        "dataset_test=make_dataset(Path('/content/drive/My Drive/DSP/data/protechn_corpus_eval/test'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "EjK83ZbabDvD",
        "outputId": "b8257f30-9b58-4050-f00e-21596f67229d"
      },
      "source": [
        "#train dataframe\n",
        "empty=[]\n",
        "for i in dataset_train:\n",
        "    \n",
        "    temp=DataFrame(i, columns=['id', 'full_sent', 'start_sent', 'end_sent', 'start_prop', 'end_prop','prop', 'ex1', 'ex2' ])\n",
        "    empty.append(temp)\n",
        "\n",
        "df_train=pd.concat(empty)  \n",
        "df_train = df_train.drop(['ex1'],axis =1).drop(['ex2'],axis =1)\n",
        "df_train.prop.value_counts()\n",
        "df_train=df_train.reset_index()\n",
        "#del df['index']\n",
        "\n",
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>id</th>\n",
              "      <th>full_sent</th>\n",
              "      <th>start_sent</th>\n",
              "      <th>end_sent</th>\n",
              "      <th>start_prop</th>\n",
              "      <th>end_prop</th>\n",
              "      <th>prop</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>7618745059</td>\n",
              "      <td>“They interpreted the law in my case to say it...</td>\n",
              "      <td>1695</td>\n",
              "      <td>1873</td>\n",
              "      <td>1831</td>\n",
              "      <td>1872</td>\n",
              "      <td>Whataboutism</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>7618745059</td>\n",
              "      <td>Two guys on my ship did the same thing and wer...</td>\n",
              "      <td>1905</td>\n",
              "      <td>1977</td>\n",
              "      <td>1925</td>\n",
              "      <td>1976</td>\n",
              "      <td>Whataboutism</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>7618745059</td>\n",
              "      <td>“They used me as an example because of [the ba...</td>\n",
              "      <td>2312</td>\n",
              "      <td>2454</td>\n",
              "      <td>2312</td>\n",
              "      <td>2388</td>\n",
              "      <td>Causal_Oversimplification</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>7618745059</td>\n",
              "      <td>The government actively destroyed his life an ...</td>\n",
              "      <td>2710</td>\n",
              "      <td>2819</td>\n",
              "      <td>2725</td>\n",
              "      <td>2782</td>\n",
              "      <td>Exaggeration,Minimisation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>7618745059</td>\n",
              "      <td>Ex-Sailor Pardoned By Trump Says He’s SUING Ob...</td>\n",
              "      <td>0</td>\n",
              "      <td>59</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index          id  ... end_prop                       prop\n",
              "0      0  7618745059  ...     1872               Whataboutism\n",
              "1      1  7618745059  ...     1976               Whataboutism\n",
              "2      2  7618745059  ...     2388  Causal_Oversimplification\n",
              "3      3  7618745059  ...     2782  Exaggeration,Minimisation\n",
              "4      4  7618745059  ...        0                          O\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDzgaXAOQ7R5"
      },
      "source": [
        "#### We define a new column (called 'label') to turn string labels into integer labels by using a defined label dictionary that maps each propaganda technique to an integer representing that class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrERNLRMb3Tc"
      },
      "source": [
        "\"\"\"\n",
        "label_dict={}\n",
        "for index, possible_label in enumerate(possible_labels):\n",
        "    label_dict[possible_label]=index\n",
        "print(label_dict)\n",
        "\"\"\"\n",
        "label_dict={'O': 0, 'Black-and-White_Fallacy': 1, 'Loaded_Language': 2, 'Flag-Waving': 3, \n",
        " 'Name_Calling,Labeling': 4, 'Slogans': 5, 'Causal_Oversimplification': 6, 'Whataboutism': 7,\n",
        " 'Exaggeration,Minimisation': 8, 'Doubt': 9, 'Appeal_to_Authority': 10, 'Repetition': 11, 'Appeal_to_fear-prejudice': 12,\n",
        " 'Thought-terminating_Cliches': 13, 'Bandwagon': 14, 'Red_Herring': 15, 'Reductio_ad_hitlerum': 16,\n",
        " 'Obfuscation,Intentional_Vagueness,Confusion': 17, 'Straw_Men': 18}\n",
        "\n",
        "df_train['label']=df_train.prop.replace(label_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "id": "SkyD-qGlb59V",
        "outputId": "cee5c375-674c-4333-b1e1-5c5c2bc66c4e"
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>id</th>\n",
              "      <th>full_sent</th>\n",
              "      <th>start_sent</th>\n",
              "      <th>end_sent</th>\n",
              "      <th>start_prop</th>\n",
              "      <th>end_prop</th>\n",
              "      <th>prop</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>7618745059</td>\n",
              "      <td>“They interpreted the law in my case to say it...</td>\n",
              "      <td>1695</td>\n",
              "      <td>1873</td>\n",
              "      <td>1831</td>\n",
              "      <td>1872</td>\n",
              "      <td>Whataboutism</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>7618745059</td>\n",
              "      <td>Two guys on my ship did the same thing and wer...</td>\n",
              "      <td>1905</td>\n",
              "      <td>1977</td>\n",
              "      <td>1925</td>\n",
              "      <td>1976</td>\n",
              "      <td>Whataboutism</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>7618745059</td>\n",
              "      <td>“They used me as an example because of [the ba...</td>\n",
              "      <td>2312</td>\n",
              "      <td>2454</td>\n",
              "      <td>2312</td>\n",
              "      <td>2388</td>\n",
              "      <td>Causal_Oversimplification</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>7618745059</td>\n",
              "      <td>The government actively destroyed his life an ...</td>\n",
              "      <td>2710</td>\n",
              "      <td>2819</td>\n",
              "      <td>2725</td>\n",
              "      <td>2782</td>\n",
              "      <td>Exaggeration,Minimisation</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>7618745059</td>\n",
              "      <td>Ex-Sailor Pardoned By Trump Says He’s SUING Ob...</td>\n",
              "      <td>0</td>\n",
              "      <td>59</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>O</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index          id  ...                       prop  label\n",
              "0      0  7618745059  ...               Whataboutism      7\n",
              "1      1  7618745059  ...               Whataboutism      7\n",
              "2      2  7618745059  ...  Causal_Oversimplification      6\n",
              "3      3  7618745059  ...  Exaggeration,Minimisation      8\n",
              "4      4  7618745059  ...                          O      0\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPz-S-Vp6vG_",
        "outputId": "3806ca7f-7127-4e29-e183-548dda72a5c8"
      },
      "source": [
        "df_train.dtypes\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "index          int64\n",
              "id            object\n",
              "full_sent     object\n",
              "start_sent     int64\n",
              "end_sent       int64\n",
              "start_prop     int64\n",
              "end_prop       int64\n",
              "prop          object\n",
              "label          int64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGrTE7Cf66YB",
        "outputId": "a9f05185-3112-4c46-fe39-6b9671b4051c"
      },
      "source": [
        "type(df_train['full_sent'][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAZbK5ZnbgPU"
      },
      "source": [
        "####Dataset is imbalanced."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdv3sqYKS00j",
        "outputId": "834780e6-4375-4f17-cd6f-51876a2b6d66"
      },
      "source": [
        "#data is not unitedly distributed in different classes i.e., we have a class imbalance\n",
        "df_train.prop.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "O                                              10337\n",
              "Loaded_Language                                 1832\n",
              "Name_Calling,Labeling                            934\n",
              "Doubt                                            527\n",
              "Repetition                                       465\n",
              "Exaggeration,Minimisation                        401\n",
              "Appeal_to_fear-prejudice                         225\n",
              "Flag-Waving                                      216\n",
              "Causal_Oversimplification                        199\n",
              "Appeal_to_Authority                              129\n",
              "Black-and-White_Fallacy                          123\n",
              "Slogans                                          123\n",
              "Thought-terminating_Cliches                       72\n",
              "Whataboutism                                      59\n",
              "Reductio_ad_hitlerum                              48\n",
              "Red_Herring                                       26\n",
              "Bandwagon                                         13\n",
              "Straw_Men                                         12\n",
              "Obfuscation,Intentional_Vagueness,Confusion       11\n",
              "Name: prop, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mo1uiBxcTA4F",
        "outputId": "5a7c46f3-e45b-447e-e2f6-79922aceff0e"
      },
      "source": [
        "df_train.label.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     10337\n",
              "2      1832\n",
              "4       934\n",
              "9       527\n",
              "11      465\n",
              "8       401\n",
              "12      225\n",
              "3       216\n",
              "6       199\n",
              "10      129\n",
              "5       123\n",
              "1       123\n",
              "13       72\n",
              "7        59\n",
              "16       48\n",
              "15       26\n",
              "14       13\n",
              "18       12\n",
              "17       11\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "HhN7qfWkcEAh",
        "outputId": "99af0931-23a5-478f-c7a9-081c5fe5d1e1"
      },
      "source": [
        "#test dataframe\n",
        "empty=[]\n",
        "for i in dataset_test:\n",
        "    \n",
        "    temp=DataFrame(i, columns=['id', 'full_sent', 'start_sent', 'end_sent', 'start_prop', 'end_prop','prop', 'ex1', 'ex2' ])\n",
        "    empty.append(temp)\n",
        "\n",
        "df_test=pd.concat(empty)  \n",
        "df_test = df_test.drop(['ex1'],axis =1).drop(['ex2'],axis =1)\n",
        "df_test.prop.value_counts()\n",
        "df_test=df_test.reset_index()\n",
        "#del df['index']\n",
        "\n",
        "df_test.head()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>id</th>\n",
              "      <th>full_sent</th>\n",
              "      <th>start_sent</th>\n",
              "      <th>end_sent</th>\n",
              "      <th>start_prop</th>\n",
              "      <th>end_prop</th>\n",
              "      <th>prop</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>111111133</td>\n",
              "      <td>CNN in turn dropped its lawsuit on the matter,...</td>\n",
              "      <td>301</td>\n",
              "      <td>415</td>\n",
              "      <td>358</td>\n",
              "      <td>367</td>\n",
              "      <td>Loaded_Language</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>111111133</td>\n",
              "      <td>But while it yielded to Mr. Acosta — whose tes...</td>\n",
              "      <td>417</td>\n",
              "      <td>673</td>\n",
              "      <td>460</td>\n",
              "      <td>465</td>\n",
              "      <td>Loaded_Language</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>111111133</td>\n",
              "      <td>But while it yielded to Mr. Acosta — whose tes...</td>\n",
              "      <td>417</td>\n",
              "      <td>673</td>\n",
              "      <td>504</td>\n",
              "      <td>507</td>\n",
              "      <td>Loaded_Language</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>111111133</td>\n",
              "      <td>The White House sought to blame Mr. Acosta for...</td>\n",
              "      <td>967</td>\n",
              "      <td>1167</td>\n",
              "      <td>1070</td>\n",
              "      <td>1077</td>\n",
              "      <td>Loaded_Language</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>111111133</td>\n",
              "      <td>Codifying the behavior of journalists struck s...</td>\n",
              "      <td>1168</td>\n",
              "      <td>1391</td>\n",
              "      <td>1224</td>\n",
              "      <td>1244</td>\n",
              "      <td>Loaded_Language</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index         id  ... end_prop             prop\n",
              "0      0  111111133  ...      367  Loaded_Language\n",
              "1      1  111111133  ...      465  Loaded_Language\n",
              "2      2  111111133  ...      507  Loaded_Language\n",
              "3      3  111111133  ...     1077  Loaded_Language\n",
              "4      4  111111133  ...     1244  Loaded_Language\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXNRjmwtcH71"
      },
      "source": [
        "\n",
        "df_test['label']=df_test.prop.replace(label_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "kiR8kpuWYwqa",
        "outputId": "70ee5594-06a6-47a6-d4d4-a38ce1cb1da4"
      },
      "source": [
        "df_test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>id</th>\n",
              "      <th>full_sent</th>\n",
              "      <th>start_sent</th>\n",
              "      <th>end_sent</th>\n",
              "      <th>start_prop</th>\n",
              "      <th>end_prop</th>\n",
              "      <th>prop</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>111111133</td>\n",
              "      <td>CNN in turn dropped its lawsuit on the matter,...</td>\n",
              "      <td>301</td>\n",
              "      <td>415</td>\n",
              "      <td>358</td>\n",
              "      <td>367</td>\n",
              "      <td>Loaded_Language</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>111111133</td>\n",
              "      <td>But while it yielded to Mr. Acosta — whose tes...</td>\n",
              "      <td>417</td>\n",
              "      <td>673</td>\n",
              "      <td>460</td>\n",
              "      <td>465</td>\n",
              "      <td>Loaded_Language</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>111111133</td>\n",
              "      <td>But while it yielded to Mr. Acosta — whose tes...</td>\n",
              "      <td>417</td>\n",
              "      <td>673</td>\n",
              "      <td>504</td>\n",
              "      <td>507</td>\n",
              "      <td>Loaded_Language</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>111111133</td>\n",
              "      <td>The White House sought to blame Mr. Acosta for...</td>\n",
              "      <td>967</td>\n",
              "      <td>1167</td>\n",
              "      <td>1070</td>\n",
              "      <td>1077</td>\n",
              "      <td>Loaded_Language</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>111111133</td>\n",
              "      <td>Codifying the behavior of journalists struck s...</td>\n",
              "      <td>1168</td>\n",
              "      <td>1391</td>\n",
              "      <td>1224</td>\n",
              "      <td>1244</td>\n",
              "      <td>Loaded_Language</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index         id  ...             prop  label\n",
              "0      0  111111133  ...  Loaded_Language      2\n",
              "1      1  111111133  ...  Loaded_Language      2\n",
              "2      2  111111133  ...  Loaded_Language      2\n",
              "3      3  111111133  ...  Loaded_Language      2\n",
              "4      4  111111133  ...  Loaded_Language      2\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgGXF7vDqGNx"
      },
      "source": [
        "\n",
        "\n",
        "####If we wanted to test this model with Augmented Data then we would be running these lines.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FbK7IG3YoJmE",
        "outputId": "19710ece-5491-4cca-c333-4b80aa48ebaa"
      },
      "source": [
        "print(\"size of train set is: \", df_train.shape[0])\n",
        "print(\"size of test set is: \", df_test.shape[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "size of train set is:  15752\n",
            "size of test set is:  4490\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8i-9fKeEqNKc"
      },
      "source": [
        "#df_new=pd.read_csv(Path(\"/content/ADD_Context.csv\"))\n",
        "#df_new.head()\n",
        "#df_new['Sentence'].isnull()\n",
        "#df_new.isnull().values.any()\n",
        "#df_new = df_new.dropna()\n",
        "#df_new.isnull().values.any()\n",
        "#df_new['label']=df_new.Label.replace(label_dict)\n",
        "#df_new = df_new.rename(columns = {'Sentence':'full_sent'})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8bvAc9BzEJZ"
      },
      "source": [
        "#df_train=df_new.iloc[0:20000, 0:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtpmVCyO0dE1"
      },
      "source": [
        "#df_train=df_train.reset_index()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAnxPUqc3UPi"
      },
      "source": [
        "#df_test=df_new.iloc[20000:, 0:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dikQ16z0clPO",
        "outputId": "9ca61434-e321-4aff-e0d1-87e268fdf197"
      },
      "source": [
        "!pip install transformers\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/db/98c3ea1a78190dac41c0127a063abf92bd01b4b0b6970a6db1c2f5b66fa0/transformers-4.0.1-py3-none-any.whl (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 5.6MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 21.7MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 30.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=f67d6c5df3a14b4c7237b79ee4a844c791c4e3f4db113af75f19a6c692b247a4\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dHao83SbkVw"
      },
      "source": [
        "###The tokenizer takes in raw text and splits it into tokens. A token in this case is a numerical number that represents a certain word. Tensordataset makes it possible to use the data set in a pytorch environment. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIsohV5WcR8t"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "from torch.utils.data import TensorDataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFQOOtbjbtVD"
      },
      "source": [
        "###We use a pretrained BERT to encode our dataset. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZKIsKhCcSZm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "3f3d508768c849ca93546aec19ef4707",
            "1e96f526187542c0a7421a335c4d88ac",
            "b412d66909e343fdb885543e9073afe8",
            "1862f780f69d4cb6b1c95db1f1702c7e",
            "283605c1bda345f39152f3b6bb584f01",
            "a9f14435d3b545bab8a302a94c4a46ac",
            "cedba0b514094f788c30827096c69a9f",
            "4c56e469c5d34e62ae77230b0bca56dc"
          ]
        },
        "outputId": "ebd9734d-2bd2-404b-a1fa-5fac4f5265f4"
      },
      "source": [
        "#we will be using all lower case data\n",
        "#do_lower_case converts every string to lower case as an uncased version of BERT will be used\n",
        "tokenizer= BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3f3d508768c849ca93546aec19ef4707",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJxs6_F6h5Po"
      },
      "source": [
        "####Now we need to convert all our sentences from language into encoded form. Batch encode class can perform this as it can take multiple strings and convert them into tokens as is needed. This is done separately for train and test data. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejywm5LKcxjy",
        "outputId": "09b03286-12d0-4926-fb2d-5d407ee19321"
      },
      "source": [
        "\"\"\" As parameters it takes actual sentences, add special tokens will highlight when a sentences ends and when a new one begins, \n",
        "an attention mask tells the model where the relevant information in a sentence lies - as sentences do not originaly have the same length \"\"\"\n",
        "\n",
        "encoded_data_train=tokenizer.batch_encode_plus(df_train.full_sent.values, add_special_tokens=True, \n",
        "                                               return_attention_mask=True, pad_to_max_length=True, max_length=256, return_tensors='pt')\n",
        "\n",
        "encoded_data_test=tokenizer.batch_encode_plus(df_test.full_sent.values, add_special_tokens=True, \n",
        "                                               return_attention_mask=True, pad_to_max_length=True, max_length=256, return_tensors='pt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hD896K-Ic0V0"
      },
      "source": [
        "\"\"\" access the data train dictionary and pull out the input ids which essetntailly represents each word as a number\"\"\"\n",
        "input_ids_train=encoded_data_train['input_ids']\n",
        "attention_masks_train=encoded_data_train['attention_mask']\n",
        "#make a tensor out of the original data labels\n",
        "labels_train=torch.tensor(df_train.label.values, dtype=torch.long)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5wtrfG4mZi_"
      },
      "source": [
        "####We create the train data set by TensorDataset which used in pytorch library.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-nlyxkgdRNn"
      },
      "source": [
        "#iterates over each three element at one time for each data set\n",
        "dataset_train=TensorDataset(input_ids_train,\n",
        "                            attention_masks_train,labels_train)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQOu2ecadVL6"
      },
      "source": [
        "#repeat for test set\n",
        "input_ids_test=encoded_data_test['input_ids']\n",
        "attention_masks_test=encoded_data_test['attention_mask']\n",
        "labels_test=torch.tensor(df_test.label.values, dtype=torch.long)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9V1wTK7dYCC"
      },
      "source": [
        "dataset_test=TensorDataset(input_ids_test,\n",
        "                            attention_masks_test,labels_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejx6K5hFn97p",
        "outputId": "f58ca922-f45e-4526-f1fa-c7c517b3bf37"
      },
      "source": [
        "print(len(dataset_train))\n",
        "print(len(dataset_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15752\n",
            "4490\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1mk-HhsofCU"
      },
      "source": [
        "####We import the pretrained BERT model from module Huggingface's transformer library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQBOM9WHda26"
      },
      "source": [
        "from transformers import BertForSequenceClassification"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrEnu414sdbI"
      },
      "source": [
        "####In this part we can as well fine tune the pretrained BERT by outlining number of labels the final layer of BERT should have. We add a layer on top of that of size 19 as a classifier. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222,
          "referenced_widgets": [
            "ec0151086a6b4ad290badde1cf42563d",
            "b755eb914c8741c8a3f45830c75c8162",
            "b0554325507447258133dfffa3e3cd05",
            "eeee01d649224622b319b8affc0fcfa4",
            "3d0c3db2d49945109c326f8c73e120ef",
            "c6357afd5b104d35ae478b56237614cf",
            "c76e6c3afd16489e9ba044d6c8805d75",
            "92989386ef5a439a8ccb4bd092cf537b",
            "6870f8ea57f14dcbba1e27c579d81626",
            "84ec3ccb97c34519bbca1f42586cdf1e",
            "608b6a7a7fa24d95a945e57f1ee06a00",
            "c44b2d73a76244d69c8d78ea313a9a64",
            "62e42e47315a428498c9d69c4999b49a",
            "fe837a4e6dd140408964c5a41204fab5",
            "d936c7efe68b470cbbf7252fe04aab82",
            "f8ac27b1bb6f4013a4219f337a7576c3"
          ]
        },
        "id": "pKA9wnDnddEW",
        "outputId": "6cd19d21-e0d1-4907-8ded-f649401d069f"
      },
      "source": [
        "model= BertForSequenceClassification.from_pretrained(\n",
        "                'bert-base-uncased',\n",
        "                #length of the label dictionary is 19\n",
        "                 num_labels=19, \n",
        "                  output_attentions=False, \n",
        "                  #the state before the output state which won't be needed to return\n",
        "                 output_hidden_states=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ec0151086a6b4ad290badde1cf42563d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6870f8ea57f14dcbba1e27c579d81626",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXqFU2Xstqst"
      },
      "source": [
        "####Dataloaders make it possible to iterate over the dataset in batches. Randomsampler samples the data randomly per batch. This will help randomize what data the model is exposed to. Sequential sampler can be used for test set, as for test set randomly sorting the data set is not as important as the gradients are fixed already in that stage."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6p_M9aKhdfUy"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9N7u64Fidhfu"
      },
      "source": [
        "batch_size=32 \n",
        "dataloader_train=DataLoader(dataset_train, \n",
        "                            sampler=RandomSampler(dataset_train), \n",
        "                            batch_size=batch_size)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqol30ukdjjC"
      },
      "source": [
        "dataloader_test=DataLoader(dataset_test, \n",
        "                            sampler=RandomSampler(dataset_test), \n",
        "                            batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeszC9P8v3jf"
      },
      "source": [
        "####Setting the optimizer to Adam as a stochastic optimizer.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4XBiF2rdocV"
      },
      "source": [
        "from transformers import AdamW, get_linear_schedule_with_warmup"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLQtjjM3dqzz"
      },
      "source": [
        "optimizer=AdamW(\n",
        "    model.parameters(), \n",
        "    lr=1e-5, #2e-5 >5e-5\n",
        "    eps=1e-8\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esc_4HcMds2b"
      },
      "source": [
        "epochs=5\n",
        "scheduler=get_linear_schedule_with_warmup(\n",
        "    optimizer, \n",
        "    num_warmup_steps=0, \n",
        "    #how many times learning rate is set to change\n",
        "    num_training_steps=len(dataloader_train)*epochs\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uDkbJ0hdu8P"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYQh0LyhdxMR"
      },
      "source": [
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usMGxk0nzOfB"
      },
      "source": [
        "####Predictions will come in the foramt of probabilities turned into 0s and 1s. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhqUXHK0dy12"
      },
      "source": [
        "#preds=[0.9, 0.07, 0.05]--> #preds=[1, 0, 0]\n",
        "def f1_score_func(preds, labels):\n",
        "  preds_flat=np.argmax(preds, axis=1).flatten()\n",
        "  labels_flat=labels.flatten()\n",
        "  return f1_score(labels_flat, preds_flat, average='weighted')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4gKrCIKd0nH"
      },
      "source": [
        "def accuracy_per_class(preds, labels):\n",
        "  label_dict_inverse={v: k for k, v in label_dict.items()}\n",
        "\n",
        "  preds_flat=np.argmax(preds, axis=1).flatten()\n",
        "  labels_flat=labels.flatten()\n",
        "\n",
        "  for label in np.unique(labels_flat):\n",
        "    y_preds=preds_flat[labels_flat==label]\n",
        "    y_true=labels_flat[labels_flat==label]\n",
        "    print(f'Class:{label_dict_inverse[label]}')\n",
        "    print(f'Accuracy:{len(y_preds[y_preds==label])}/{len(y_true)}\\n')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AX68pajEd2ZG"
      },
      "source": [
        "import random\n",
        "seed_val=17\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4lBWC5Jd4eL",
        "outputId": "8b7a62dd-e7e4-4fb3-ca44-604c018768d5"
      },
      "source": [
        "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "#send the model to the available device\n",
        "model.to(device)\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5qB2Ldvd6fT"
      },
      "source": [
        "def evaluate(dataloader_test):\n",
        "  model.eval()\n",
        "\n",
        "  loss_test_total=0\n",
        "  predictions, true_vals=[],[]\n",
        "  \n",
        "  for batch in dataloader_test:\n",
        "      batch=tuple(b.to(device) for b in batch)\n",
        "\n",
        "      inputs={\n",
        "          'input_ids': batch[0],\n",
        "\n",
        "          'attention_mask': batch[1],\n",
        "          'labels': batch[2]\n",
        "\n",
        "      }\n",
        "      with torch.no_grad():\n",
        "        outputs=model(**inputs)\n",
        "\n",
        "      loss=outputs[0]\n",
        "      logits= outputs[1]\n",
        "      loss_test_total +=loss.item()\n",
        "      #loss.backward()\n",
        "\n",
        "      logits=logits.detach().cpu().numpy()\n",
        "      label_ids=inputs['labels'].cpu().numpy()\n",
        "      predictions.append(logits)\n",
        "      true_vals.append(label_ids)\n",
        "\n",
        "\n",
        "\n",
        "      \n",
        "  loss_test_avg=loss_test_total/len(dataloader_test)\n",
        "\n",
        "  predictions=np.concatenate(predictions, axis=0)\n",
        "  true_vals=np.concatenate(true_vals, axis=0)\n",
        "\n",
        "\n",
        "  return loss_test_avg, predictions, true_vals\n",
        "  \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfwkycH4d9P3",
        "outputId": "fcc9eb25-1449-4c3b-9fb3-893a047e0373"
      },
      "source": [
        "pip install tqdm\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.41.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1--8cz-od_xE"
      },
      "source": [
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKfc0E9aeB0D",
        "outputId": "dae3ca61-e92f-43a6-9291-4385ac0f7eb8"
      },
      "source": [
        "for  epoch in tqdm(range(1, epochs+1)):  \n",
        "  \n",
        "  model.train()\n",
        "\n",
        "  loss_train_total=0\n",
        "\n",
        "  progress_bar=tqdm(dataloader_train, \n",
        "                    desc='Epoch {:1d}'.format(epoch), \n",
        "                    leave=False, \n",
        "                    disable=False)\n",
        "                    \n",
        "  for batch in progress_bar:\n",
        "      model.zero_grad()\n",
        "      batch=tuple(b.to(device) for b in batch)\n",
        "      inputs={\n",
        "          'input_ids': batch[0],\n",
        "\n",
        "          'attention_mask': batch[1],\n",
        "          'labels': batch[2]\n",
        "\n",
        "      }\n",
        "      #with torch.no_grad():\n",
        "      outputs=model(**inputs)\n",
        "\n",
        "      loss=outputs[0]\n",
        "      loss_train_total +=loss.item()\n",
        "      loss.backward()\n",
        "\n",
        "\n",
        "\n",
        "      torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "      optimizer.step()\n",
        "      scheduler.step()\n",
        "      progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch) )})\n",
        "  torch.save(model.state_dict(), f'/content/BERT_ft_epoch{epoch}.model')\n",
        "  tqdm.write('\\nEpoch {epoch}')\n",
        "  loss_train_avg=loss_train_total/len(dataloader_train)\n",
        "  tqdm.write(f'Training loss:{loss_train_avg}')\n",
        "  val_loss, predictions, true_vals=evaluate(dataloader_test)\n",
        "\n",
        "  val_f1=f1_score_func(predictions, true_vals)\n",
        "  tqdm.write(f'Validation loss: {val_loss}')\n",
        "  tqdm.write(f'F1 Score (weighted): {val_f1}')\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/5 [00:00<?, ?it/s]\n",
            "Epoch 1:   0%|          | 0/493 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 1:   0%|          | 0/493 [01:30<?, ?it/s, training_loss=1.099]\u001b[A\n",
            "Epoch 1:   0%|          | 1/493 [01:30<12:21:59, 90.49s/it, training_loss=1.099]\u001b[A"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRYfEBY0kHla",
        "outputId": "0540f8c9-776d-4ea2-851a-399e8ba9b92a"
      },
      "source": [
        "model=BertForSequenceClassification.from_pretrained(\n",
        "                'bert-base-uncased',\n",
        "                 num_labels=19, \n",
        "                  output_attentions=False, \n",
        "                 output_hidden_states=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUUm-quRI-Z8"
      },
      "source": [
        "####We choose the model from the last epoch, here the 8th epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTOm43XIkO51",
        "outputId": "01996b9a-bad3-4892-ddad-922f2132d192"
      },
      "source": [
        "model.load_state_dict(torch.load('/content/BERT_ft_epoch5.model', map_location=torch.device('cuda')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChkyrFghkdBO",
        "outputId": "29d5de9f-cde8-45c3-d9a9-766190bc5217"
      },
      "source": [
        "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model.to(device)\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HCzzIW9kr1x"
      },
      "source": [
        "_, prediction, true_vals= evaluate(dataloader_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwlOPdROHn8o"
      },
      "source": [
        "####F1 score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCX_pfXdI3IU",
        "outputId": "ae01c948-1a67-498b-82ba-190d19a831bf"
      },
      "source": [
        "f1_score_func(prediction, true_vals)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6351770948862572"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmZBkB1MIxR9",
        "outputId": "e6ad5bae-815d-4102-ce13-ed4039d8f837"
      },
      "source": [
        "accuracy_per_class(prediction, true_vals)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class:O\n",
            "Accuracy:2821/3000\n",
            "\n",
            "Class:Black-and-White_Fallacy\n",
            "Accuracy:0/26\n",
            "\n",
            "Class:Loaded_Language\n",
            "Accuracy:236/436\n",
            "\n",
            "Class:Flag-Waving\n",
            "Accuracy:12/96\n",
            "\n",
            "Class:Name_Calling,Labeling\n",
            "Accuracy:38/209\n",
            "\n",
            "Class:Slogans\n",
            "Accuracy:0/36\n",
            "\n",
            "Class:Causal_Oversimplification\n",
            "Accuracy:0/33\n",
            "\n",
            "Class:Whataboutism\n",
            "Accuracy:0/25\n",
            "\n",
            "Class:Exaggeration,Minimisation\n",
            "Accuracy:7/99\n",
            "\n",
            "Class:Doubt\n",
            "Accuracy:2/89\n",
            "\n",
            "Class:Appeal_to_Authority\n",
            "Accuracy:0/56\n",
            "\n",
            "Class:Repetition\n",
            "Accuracy:1/195\n",
            "\n",
            "Class:Appeal_to_fear-prejudice\n",
            "Accuracy:3/130\n",
            "\n",
            "Class:Thought-terminating_Cliches\n",
            "Accuracy:0/22\n",
            "\n",
            "Class:Bandwagon\n",
            "Accuracy:0/4\n",
            "\n",
            "Class:Red_Herring\n",
            "Accuracy:0/15\n",
            "\n",
            "Class:Reductio_ad_hitlerum\n",
            "Accuracy:0/11\n",
            "\n",
            "Class:Obfuscation,Intentional_Vagueness,Confusion\n",
            "Accuracy:0/6\n",
            "\n",
            "Class:Straw_Men\n",
            "Accuracy:0/2\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSB4P1mbs4Hb",
        "outputId": "368d46f2-5f9f-4c32-da6f-c2fb570dc79d"
      },
      "source": [
        "print(len(prediction))\n",
        "assert(len(predictions)==len(df_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4490\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SM3yxtEmtA3G",
        "outputId": "459f9d50-7451-46e9-992a-2dfb60ec9d22"
      },
      "source": [
        "a=prediction[4000]\n",
        "print(\"an example of the predicted vectors is: \", a)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "an example of the predicted vectors is:  [ 6.3453336  -1.077924    0.657036   -0.857547    0.21784805 -0.58260053\n",
            " -0.5905076  -1.0472031  -0.32378218  0.6990846   0.1088158   0.63251996\n",
            " -0.60680425 -0.88674796 -1.3269558  -1.2315438  -1.1710534  -1.3416458\n",
            " -1.3956172 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJdU6LJGt8h1"
      },
      "source": [
        "pred=[]\n",
        "for i in range (len(prediction)):\n",
        "  pred.append(np.argmax(prediction[i]).flatten())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1XJMsPhveeq",
        "outputId": "078260ef-d554-4ab8-fd38-9b7e8f273b09"
      },
      "source": [
        "print(pred[9])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rab8IUd9s7XZ",
        "outputId": "8ea0cf07-0b89-486f-a0cc-7e1bd2d27292"
      },
      "source": [
        "print(len(true_vals))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4490\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pZoy_6Rs9vZ",
        "outputId": "939aaee6-36cc-429c-8d5e-b260ba5af8d9"
      },
      "source": [
        "print(true_vals[1000])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKs79LOiqIJU",
        "outputId": "9f206e30-1392-4d66-b066-d75ccc67df21"
      },
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support as score\n",
        "\n",
        "#predicted = [1,2,3,4,5,1,2,1,1,4,5] \n",
        "#y_test = [1,2,3,4,5,1,2,1,1,4,1]\n",
        "\n",
        "precision, recall, fscore, support = score(true_vals, pred)\n",
        "\n",
        "#print('precision: {}'.format(precision))\n",
        "#print('recall: {}'.format(recall))\n",
        "#print('fscore: {}'.format(fscore))\n",
        "#print('support: {}'.format(support))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJO3g3huxhzu"
      },
      "source": [
        "df1 = pd.DataFrame({ 'precision': precision, 'recall':recall, 'Fscore':fscore, 'support':support })\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8ifEK--xnip",
        "outputId": "6dfa2243-e130-46b4-a5b5-95532a2ffe24"
      },
      "source": [
        "df1.head\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of     precision    recall    Fscore  support\n",
              "0    0.795544  0.940333  0.861900     3000\n",
              "1    0.000000  0.000000  0.000000       26\n",
              "2    0.342029  0.541284  0.419183      436\n",
              "3    0.363636  0.125000  0.186047       96\n",
              "4    0.248366  0.181818  0.209945      209\n",
              "5    0.000000  0.000000  0.000000       36\n",
              "6    0.000000  0.000000  0.000000       33\n",
              "7    0.000000  0.000000  0.000000       25\n",
              "8    0.269231  0.070707  0.112000       99\n",
              "9    0.105263  0.022472  0.037037       89\n",
              "10   0.000000  0.000000  0.000000       56\n",
              "11   0.100000  0.005128  0.009756      195\n",
              "12   0.230769  0.023077  0.041958      130\n",
              "13   0.000000  0.000000  0.000000       22\n",
              "14   0.000000  0.000000  0.000000        4\n",
              "15   0.000000  0.000000  0.000000       15\n",
              "16   0.000000  0.000000  0.000000       11\n",
              "17   0.000000  0.000000  0.000000        6\n",
              "18   0.000000  0.000000  0.000000        2>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0VjLhfEybxS",
        "outputId": "802645c7-d4b4-46b4-f091-2bb12368cb13"
      },
      "source": [
        "from tabulate import tabulate\n",
        "\n",
        "print(tabulate(df1, headers='keys', tablefmt='psql'))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----+-------------+------------+-----------+-----------+\n",
            "|    |   precision |     recall |    Fscore |   support |\n",
            "|----+-------------+------------+-----------+-----------|\n",
            "|  0 |    0.795544 | 0.940333   | 0.8619    |      3000 |\n",
            "|  1 |    0        | 0          | 0         |        26 |\n",
            "|  2 |    0.342029 | 0.541284   | 0.419183  |       436 |\n",
            "|  3 |    0.363636 | 0.125      | 0.186047  |        96 |\n",
            "|  4 |    0.248366 | 0.181818   | 0.209945  |       209 |\n",
            "|  5 |    0        | 0          | 0         |        36 |\n",
            "|  6 |    0        | 0          | 0         |        33 |\n",
            "|  7 |    0        | 0          | 0         |        25 |\n",
            "|  8 |    0.269231 | 0.0707071  | 0.112     |        99 |\n",
            "|  9 |    0.105263 | 0.0224719  | 0.037037  |        89 |\n",
            "| 10 |    0        | 0          | 0         |        56 |\n",
            "| 11 |    0.1      | 0.00512821 | 0.0097561 |       195 |\n",
            "| 12 |    0.230769 | 0.0230769  | 0.041958  |       130 |\n",
            "| 13 |    0        | 0          | 0         |        22 |\n",
            "| 14 |    0        | 0          | 0         |         4 |\n",
            "| 15 |    0        | 0          | 0         |        15 |\n",
            "| 16 |    0        | 0          | 0         |        11 |\n",
            "| 17 |    0        | 0          | 0         |         6 |\n",
            "| 18 |    0        | 0          | 0         |         2 |\n",
            "+----+-------------+------------+-----------+-----------+\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}